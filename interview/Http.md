## HTTP 是什么？
HTTP：HyperText Transfer Protocol，**超文本传输协议**，是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范。


## HTTP 发展历史
1. **HTTP/0.9**

    发布于 1991 年，功能简单，只支持 GET 请求方式，只支持纯文本内容传输，已过时。

2. **HTTP/1.0**
   
    + 任何格式的内容都可以发送，包括文字，图像，视频，二进制文件等。
    + 引入了 POST 和 HEAD 请求方式。
    + 请求报文和响应报文的格式改变，增加请求头(header)信息，用于描述一些元数据。
    + 只使用 header 中的 If-Modified-Since 和 Expires 作为缓存失效的标准。
    + 不支持断点续传，也就是说，每次都会传送全部的页面和数据。
+ 通常每台计算机只能绑定一个 IP，所以请求消息中的 URL 并没有传递主机名(hostname)。
  
3. **HTTP/1.1**

    1999 年发布至今，仍是最主流的 HTTP 版本协议。

    + 引入持久连接(persistent connection)，即 TCP 连接默认不关闭，可以被多个请求复用，不用声明 Connection: keep-alive。长连接的连接时长可以通过请求头中的 keep-alive 字段来设置。
    + 引入了管道机制(pipelining)，即在同一个 TCP 连接里，客户端可以同时发送多个请求，进一步改进了 HTTP 协议的效率。
    + 新增加了 E-tag，If-Unmodified-Since, If-Match, If-None-Match 等缓存控制标头来控制缓存失效。
    + 支持断点续传，通过使用请求头中的 Range 来实现。
    + 使用了虚拟网络，在一台物理服务器上可以存在多个虚拟主机(Multi-homed Web Servers)，并且它们共享一个 IP 地址。
    + 新增请求方法：PUT、PATCH、OPTIONS、DELETE。

4. **HTTP/2.0**
   
    + 二进制分帧：这是一次彻底的二进制协议，头信息和数据体都是二进制，并且统称为"帧"：头信息帧和数据帧。
    + 头部压缩：HTTP 1.1 版本会出现「User-Agent、Cookie、Accept、Server、Range」等字段可能会占用几百甚至几千字节，而 Body 却经常只有几十字节，所以导致头部偏重。HTTP 2.0 使用 HPACK 算法进行压缩。
    + 多路复用：复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，这样子解决了队头阻塞的问题。
    + 服务器推送：允许服务器未经请求，主动向客户端发送资源，即服务器推送。
+ 请求优先级：可以设置数据帧的优先级，让服务端先处理重要资源，优化用户体验。
  
5. **HTTP/3.0**

    基于 **QUIC 协议**，Google 搞的一个基于 UDP 协议的协议。

    QUIC 的新功能：
    + 0-RTT：0-RTT 建立连接可以说是 QUIC 相比 HTTP2 最大的性能优势。
    + 多路复用：QUIC 原生就实现了这个功能，并且传输的单个数据流可以保证有序交付且不会影响其他的数据流。
    + 加密认证的报文：除了个别报文比如 PUBLIC_RESET 和 CHLO，所有报文头部都是经过认证的，报文 Body 都是经过加密的。
    + 向前纠错机制：每个数据包除了它本身的内容之外，还包括了部分其他数据包的数据，因此少量的丢包可以通过其他包的冗余数据直接组装而无需重传。


## HTTP 报文结构是怎样的？

    "起始行 + 头部 + 空行 + 实体"

1. **起始行**

    请求报文的起始行也叫作 "请求行"，由 "方法 + 路径 + http版本" 组成。
    ```http
    GET /home/index.html http/1.1
    ```
    响应报文的起始行也叫作 "响应行"，由 "http版本 + 状态码 + 描述" 组成。
    ```http
    http/1.1 200 OK
    ```
    注意：在起始行中，每两个部分之间用空格隔开，最后一个部分后面应该接一个换行(CRLF)，严格遵循 ABNF 语法规范。


2. **头部**

    头部信息的格式：

    (1) 字段名不区分大小写

    (2) 字段名不允许出现空格，不可以出现下划线 _

    (3) 字段名后面必须紧接着 :


3. **空行**

    用来区分开头部和实体。

    空行后的内容全部被视为实体。


4. **实体**

    具体的数据，也就是 body 部分。请求报文对应请求体, 响应报文对应响应体。


## 请求方法
  **GET**：请求获取 Request-URI 所标识的资源(获取数据)。

  **POST**：在 Request-URI 所标识的资源后附加新的数据(上传数据)。

  **HEAD**：请求获取由 Request-URI 所标识的资源的响应消息报头。

  **PUT**：请求服务器存储一个资源，并用 Request-URI 作为其标识(修改数据)。

  **DELETE**：请求服务器删除对应所标识的资源。

  **CONNECT**：建立连接隧道，用于代理服务器。

  **OPTIONS**：列出可对资源实行的请求方法，用来跨域请求。

  **TRACE**：追踪请求-响应的传输路径，主要用于测试或诊断。


## HTTP 状态码

RFC 规定 HTTP 的状态码为「三位数」，第一个数字定义了响应的类别，被分为五类:

「1xx」: 代表请求已被接受，需要继续处理。

「2xx」: 表示成功状态。

「3xx」: 重定向状态，资源位置发生了变动，需要重新请求。

「4xx」: 客户端错误。

「5xx」: 服务器端错误。

  **200** OK 表示从客户端发来的请求在服务器端被正确请求。

  204 No content，表示请求成功，但没有资源可返回。

  **206** Partial Content，该状态码表示客户端进行了 Range 请求，而服务器成功执行了这部分的 GET 请求 响应报文中包含由 「Content-Range」 指定范围的实体内容。


  **301** Moved Permanently，永久性重定向，表示资源已被分配了新的 URL，这时应该按 Location 首部字段提示的 URI 重新保存。(这个时候浏览器默认会做缓存优化，在第二次访问的时候自动访问重定向的那个地址。)

  **302** Found，临时性重定向，表示资源临时被分配了新的 URL。

  303 See Other，表示资源存在着另一个 URL，应使用 GET 方法获取资源。

  **304** Not Modified，当协商缓存命中时会返回这个状态码。

  307 Temporary Redirect，临时重定向，和 302 含义相同，不会改变 method。


  **400** Bad Request，请求报文存在语法错误。

  401 Unauthorized，表示发送的请求需要有通过 HTTP 认证的认证信息。

  **403** Forbidden，表示对请求资源的访问被服务器拒绝。

  **404** Not Found，表示在服务器上没有找到请求的资源。

  405 Method Not Allowed，服务器禁止使用该请求方法，客户端可以通过 OPTIONS 方法来查看服务器允许的访问方法。

  406 Not Acceptable: 资源无法满足客户端的条件。

  408 Request Timeout: 响应超时，服务器等待了太长时间。

  409 Conflict: 多个请求发生了冲突。

  413 Request Entity Too Large: 请求体的数据过大。

  414 Request-URI Too Long: 请求行里的 URI 太大。

  429 Too Many Request: 客户端发送的请求过多。

  431 Request Header Fields Too Large：请求头的字段内容太大。


  **500** Internal Server Error: 表示服务器端在响应请求时发生了错误。

  501 Not Implemented: 表示客户端请求的功能还不支持。

  502 Bad Gateway: 服务器自身是正常的，但访问的时候出错了，无法知晓具体错误信息。

  **503** Service Unavailable: 表示服务器当前很忙，暂时无法响应服务。


注意：当 301、302、303 响应状态码返回时，几乎所有的浏览器都会把 POST 改成 GET，并删除请求报文内的主体，之后请求会自动再次发送。301、302 标准是禁止将 POST 方法改变成 GET 方法的，但实际使用时大家都会这么做。


## HTTP 数据传输

**定长包体**

对于定长包体而言，发送端在传输的时候一般会带上 Content-Length, 来指明包体的长度。

**不定长包体**

通过 Transfer-Encoding: chunked，表示分块传输数据，设置这个字段后会自动产生两个效果：
+ Content-Length 字段会被忽略 
+ 基于长连接持续推送动态内容。

如果头部信息中有 Transfer-Encoding，优先采用 Transfer-Encoding 里面的方法来找到对应的长度。


## HTTP 缓存
缓存是一种保存资源副本并在下次请求时直接使用该副本的技术。

一般来说有浏览器缓存、代理缓存、CDN、网关缓存、反向代理缓存和负载均衡器等部署在服务器上的缓存方式。

常见的 HTTP 缓存**只能存储 GET 响应**，对于其他类型的响应则无能为力。缓存的关键主要包括 request method 和目标 URI（一般只有 GET 请求才会被缓存）。

**浏览器缓存**

+ **强缓存**

    检查强缓存，这个阶段**不需要发送HTTP请求**。通过查找相应的字段来进行，在不同的 HTTP 版本中字段不同：HTTP/1.0：Expires  HTTP/1.1：Cache-Control。

    + **Expires**

        表示**过期时间**，存在于响应头中，告诉浏览器在这个过期时间之前可以从缓存中直接获取数据，无需请求。
    
        ```http
        // 表示资源在 2020 年 11 月 22 号 8 点 12 分过期
        Expires: Wed, 22 Nov 2020 08:12:00 GMT
        ```
        存在的**问题**：服务器的时间和浏览器的时间可能并不一致，导致有可能获取不到最新的内容。
        
    + **Cache-Control**

        缓存控制，采用**过期时长**来控制缓存，对应的字段的 max-age。
        ```http
        // 表示这个响应返回后在 3600 秒，也就是一个小时之内可以直接使用缓存
        Cache-Control: max-age=3600
        ```

        Cache-Control 还包括一些其他的字段：
        - public：客户端和代理服务器都可以缓存。
        - private：只有浏览器能缓存了，中间的代理服务器不能缓存。
        - no-cache：跳过当前的强缓存，发送 HTTP 请求，即直接进入协商缓存阶段。
        - no-store：不进行任何形式的缓存。
        - s-maxage：针对代理服务器的缓存时间。
        - must-revalidate：是缓存就会有过期的时候，加上这个字段一旦缓存过期，就必须回到源服务器验证。
    
        注意：当 Expires 和 Cache-Control 同时存在的时候，会**优先考虑 Cache-Control**。

        源服务器在设置完 Cache-Control 后**必须**要为报文加上 Last-modified 或 ETag 字段。
    
+ **协商缓存**

    强缓存失效之后，浏览器在请求头中携带相应的缓存 tag 来向服务器发请求，由服务器根据这个 tag 来决定是否使用缓存，这就是协商缓存。
    
    这样的缓存 tag 分为两种: Last-Modified 和 ETag。这两者各有优劣，并不存在谁对谁有绝对的优势。

    + **Last-Modified**，资源的最后修改时间

        在浏览器第一次给服务器发送请求后，服务器会在响应头中加上这个字段。

        浏览器接收到后，如果再次请求，会在请求头中携带 If-Modified-Since 字段(Last-Modified)，这个字段的值也就是服务器传来的最后修改时间。
        
        服务器拿到请求头中的 If-Modified-Since 的字段后，其实会和这个服务器中该资源的最后修改时间对比。
    
        如果请求头中的这个值小于最后修改时间，说明是时候更新了，返回新的资源。否则返回 304，告诉浏览器直接用缓存。
    
    + **Etag**：服务器根据当前文件的内容，给文件生成的唯一标识，只要里面的内容有改动，这个值就会发生改变

        服务器通过响应头把这个值给浏览器。

        浏览器接收到 ETag 的值，会在下次请求时，将这个值作为 If-None-Match 这个字段(Etag)的内容，并放到请求头中，然后发给服务器。

        服务器接收到 If-None-Match 后，会跟服务器上该资源的 ETag 进行比对。

        如果两者不一样，说明资源更新了，返回新的资源。否则返回 304，告诉浏览器直接用缓存。

    + **Last-Modified 与 Etag 对比**：
      
        + 在**精准度**上，ETag 优于 Last-Modified。
          
            ETag 是按照内容给资源上标识，因此能准确感知资源的变化。
            
            Last-Modified 就不一样了，它在一些特殊的情况并不能准确感知资源变化。
            
            主要有两种情况：
            
            - 编辑了资源文件，但是文件内容并没有更改，这样也会造成缓存失效。
            - Last-Modified 能够感知的单位时间是 s，如果文件在 1s 内改变了多次，那么这时候的 Last-Modified 就不能体现出修改了。

        + 在**性能**上，Last-Modified 优于 ETag，Last-Modified 仅仅只是记录一个时间点，而 Etag 需要根据文件的具体内容生成哈希值。

    注意：当两种方式都支持的话，服务器会**优先考虑** ETag。

+ **缓存位置**
  

浏览器缓存的位置可以分为四种，优先级从高到低排列分别：Service Worker > Memory Cache > Disk Cache > Push Cache。
    
    + **Service Worker**
    
    Service Worker 借鉴了 Web Worker 的 思路，即**让 JS 运行在主线程之外**，由于它脱离了浏览器的窗体，因此**无法直接访问DOM**。
    
    Service Worker 与浏览器其他内建的缓存机制不同，它可以让我们自由控制缓存哪些文件、如何匹配缓存、如何读取缓存，并且缓存是持续性的。
    
    它能帮助我们完成很多有用的功能，比如离线缓存、消息推送和网络代理等功能。其中的离线缓存就是 Service Worker Cache。
    
    Service Worker 同时也是 PWA 的重要实现机制。

+ **Memory Cache**
        
    内存缓存，从效率上讲它是最快的。但是从存活时间来讲又是最短的，当**渲染进程结束后**，内存缓存也就不存在了。
    
    + **Disk Cache**
      
    
    存储在磁盘中的缓存，从存取效率上讲是比内存缓存慢的，优势在于存储容量和存储时长。
    
+ **Push Cache**
        
        推送缓存，这是浏览器缓存的最后一道防线。它是 HTTP/2 中的内容。
    
    注意：在 Memory Cache 和 Disk Cache 的选择上，如果当前系统**内存使用率高**的话，文件优先进入磁盘；同时比**较大的文件优先存入磁盘**，反优先存入内存。
    
+ **总结**
  
    + 首先检查 Cache-Control 字段，如果 max-age 未到，直接使用强缓存
    + 否则进入协商缓存，发送 HTTP 请求，检查请求头中的 If-Modified-Since 或 If-None-Match 字段判断资源是否发生了更新
        - 若资源更新，返回资源和 200
        - 否则返回 304，告诉浏览器直接从协商缓存获取资源


## HTTP 缓存代理
**HTTP 代理**

代理服务本身不生产内容，而是处于中间位置转发上下游的请求和响应，具有双重身份：

+ 面向下游的用户时，表现为服务器，代表源服务器响应客户端的请求
+ 面向上游的源服务器时，又表现为客户端，代表客户端发送请求

代理的功能：

+ 负载均衡

+ 健康检查：使用“心跳”等机制监控后端服务器，发现有故障就及时“踢出”集群，保证服务高可用
+ 安全防护：保护被代理的后端服务器，限制 IP 地址或流量，抵御网络攻击和过载
+ 加密卸载：对外网使用 SSL/TLS 加密通信认证，而在安全的内网不加密，消除加解密成本
+ 数据过滤：拦截上下行的数据，任意指定策略修改请求或者响应
+ 内容缓存

**代理相关头字段**

代理服务器需要用 **Via 字段**标明代理的身份 (Via 是一个通用字段，请求头或响应头里都可以出现)。

如果通信链路中有很多中间代理，就会在 Via 里形成一个链表，这样就可以知道报文究竟走过了多少个环节才到达了目的地。

Via 字段**只解决了客户端和源服务器判断是否存在代理的问题**，还不能知道对方的真实信息。

通常服务器需要知道客户端的真实 IP 地址，方便做访问控制、用户画像、统计分析。但HTTP 标准里并没有为此定义头字段，但已经出现了很多“事实上的标准”。

最常用的两个头字段是 X-Forwarded-For 和 X-Real-IP：

+ **X-Forwarded-For** 

  意思是“**为谁而转发**”，形式上和 Via 差不多，每经过一个代理节点就会在字段里追加一个信息。但 Via 追加的是代理主机名（或者域名），而 X-Forwarded-For 追加的是请求方的 IP 地址。所以，在字段里最左边的 IP 地址就是客户端的地址。

+ **X-Real-IP** 

  记录客户端 IP 地址，不记录中间的代理信息，相当于是 X-Forwarded-For 的简化版。如果客户端和源服务器之间只有一个代理，那么这两个字段的值就是相同的。

**代理协议**

只是事实标准，不是 RFC

    PROXY TCP4 1.1.1.1 2.2.2.2 55555 80\r\n
    GET / HTTP/1.1\r\n
    Host: www.xxx.com\r\n
    \r\n

开头必须是 **PROXY** 五个大写字母，然后是 TCP4 或者 TCP6，表示客户端的 IP 地址类型，再后面是请求方地址、应答方地址、请求方端口号、应答方端口号，最后用一个回车换行（\r\n）结束。

服务器看到这样的报文，只要解析第一行就可以拿到客户端地址，不需要再去理会后面的 HTTP 数据。

**HTTP 缓存代理**

HTTP 缓存代理就是**支持缓存控制的代理服务**。

对于源服务器来说，它也是有缓存的，比如 Redis, Memcache，但对于 HTTP 缓存来说，如果每次客户端缓存失效都要到源服务器获取，那给源服务器的压力是很大的。

由此引入了缓存代理的机制。让代理服务器接管一部分的服务端HTTP缓存，客户端缓存过期后就近到代理缓存中获取，代理缓存过期了才请求源服务器，这样流量巨大的时候能明显降低源服务器的压力。

缓存代理的控制分为两部分，一部分是源服务器端的控制，一部分是客户端的控制。
+ **源服务器的缓存控制**
  
    + **private 和 public**
    
      在源服务器的响应头中，会加上 Cache-Control 这个字段进行缓存控制字段，那么它的值当中可以加入 private 或者 public 表示是否允许代理服务器缓存，前者禁止，后者为允许。
    
    + **proxy-revalidate**
    
      must-revalidate 表示客户端缓存过期就去源服务器获取，而 proxy-revalidate 则表示代理服务器的缓存过期后到源服务器获取。
    
    + **s-maxage**
    
      限定了缓存在代理服务器的有效时间。
    
    + **no-transform**
    
      代理有时候会对缓存下来的数据做一些优化，比如把图片生成 png、webp 等几种格式，方便今后的请求处理，而 no-transform 会禁止这样做。
+ **客户端的缓存控制**
  
    + 在客户端的请求头中，可以加入这两个字段，来**对代理服务器上的缓存进行宽容和限制操作**。
        - **max-stale**
        
          表示客户端到代理服务器上拿缓存的时候，即使代理缓存过期了也不要紧，只要过期时间在 max-stale 规定的时间内，还是可以从代理中获取的。
        
        - **min-fresh**
        
          表示代理缓存需要一定的提前量(提前量新鲜度)，不要等到缓存刚好到期再获取，一定要在到期前，即 min-fresh 规定的时间之前去获取，否则获取不到。
        
    + **only-if-cached**
    
        这个字段加上后表示客户端只会接受代理缓存，而不会接受源服务器的响应。如果代理缓存无效，则直接返回 504(Gateway Timeout)。

**Vary 字段**

它是内容协商的结果，相当于报文的一个**版本标记**。

同一个请求，经过内容协商后可能会有不同的字符集、编码、浏览器等版本。

比如，“Vary: Accept-Encoding” “Vary: User-Agent”，**缓存代理必须要存储这些不同的版本**。

当再收到相同的请求时，代理就读取缓存里的 Vary，对比请求头里相应的 Accept-Encoding、User-Agent等字段，如果和上一个请求的完全匹配，比如都是 gzip、Chrome，就表示版本一致，可以返回缓存的数据。

**Purge(缓存清理)**

+ 过期的数据应该及时淘汰，避免占用空间
+ 源站的资源有更新，需要删除旧版本，主动换成最新版（即刷新）
+ 有时候会缓存了一些本不该存储的信息，例如网络谣言或者危险链接，必须尽快把它们删除

**清理缓存**的方法有很多，比较常用的一种做法是使用自定义请求方法 **PURGE**，发给代理服务器，要求删除 URI 对应的缓存数据。


## HTTP/1.1 特点和缺点
1. 特点
    + **灵活可扩展**
    
      主要体现在两个方面：
    
  + 一个是语义上的自由，只规定了基本格式，其他的各个部分都没有严格的语法限制。
      + 一个是传输形式的多样性，不仅仅可以传输文本，还能传输图片、视频等任意数据，非常方便。
      
    + **可靠传输**
    
      HTTP 基于 TCP/IP，因此把这一特性继承了下来。
    
    + **请求-应答模式**
    
      意思是一发一收、有来有回，当然这个请求方和应答方不单单指客户端和服务器之间，如果某台服务器作为代理来连接后端的服务端，那么这台服务器也会扮演请求方的角色。
    
    + **无状态**
    
      状态是指通信过程的上下文信息，而每次 HTTP 请求都是独立、无关的，默认不需要保留状态信息。
    
2. 缺点
    + **无状态**
    
      无状态是视场景而言的：
    
      + 在需要长连接的场景中，需要保存大量的上下文信息，以免传输大量重复的信息，此时无状态就是 HTTP 的缺点。
    
      + 若只是为了获取数据，不需要保存连接上下文信息，无状态会减少了网络开销，成为了 HTTP 的优点。
    
    + **明文传输**
    
      协议里的报文（主要指的是头部）不使用二进制数据，而是文本形式。让 HTTP 的报文信息暴露给了外界，给攻击者也提供了便利。(**WIFI 陷阱**就是利用 HTTP 明文传输的缺点)
    
    + **队头阻塞问题**
    
      当 HTTP 开启长连接时，共用一个 TCP 连接，同一时刻只能处理一个请求，那么当前请求耗时过长的情况下，其它的请求只能处于阻塞状态。



## HTTP/2
HTTP/2 当中废除了起始行的概念，将起始行中的请求方法、URI、状态码转换成了头字段，不过这些字段都有一个":"前缀，用来和其它请求头区分开。

1. **头部压缩**
   

HTTP/1.1 及之前版本，请求体一般会有响应的压缩编码过程，通过 Content-Encoding 头部字段来指定。
    
当请求字段非常复杂的时候，尤其对于 GET 请求，请求报文几乎全是请求头（尤其是携带大量 Cookie），这时还是存在非常大的优化空间的。
    
    所以 HTTP/2 针对头部字段，也采用了相应的压缩算法 — **HPACK**，对请求头进行压缩。
    
    HPACK 算法的亮点：
    + 在服务器和客户端之间建立**哈希表**，将用到的字段存放在这张表中，那么在传输的时候对于之前出现过的值，只需要把索引(比如0，1，2，...)传给对方即可，对方拿到索引查表就行了。这种传索引的方式，可以说让请求头字段得到极大程度的精简和复用。
+ 对于**整数和字符串进行哈夫曼编码**，哈夫曼编码的原理就是先将所有出现的字符建立一张索引表，然后让出现次数多的字符对应的索引尽可能短，传输的时候也是传输这样的索引序列，可以达到非常高的压缩率。
  
2. **二进制帧**

    头部数据压缩之后，HTTP/2 就把报文拆成二进制的帧准备发送。

    帧开头是 3 个字节的长度（但不包括头的 9 个字节），默认上限是 2^14，最大是 2^24，也就是说 HTTP/2 的帧通常不超过 16K，最大是 16M。

    长度后面的一个字节是帧类型，大致可以分成数据帧和控制帧两类，HEADERS 帧和 DATA 帧属于数据帧，存放的是 HTTP 报文，而 SETTINGS、PING、PRIORITY 等则是用来管理流的控制帧。

    HTTP/2 总共定义了 10 种类型的帧，但一个字节可以表示最多 256 种，所以也允许在标准之外定义其他类型实现功能扩展。这就有点像 TLS 里扩展协议的意思了，比如 Google 的 gRPC 就利用了这个特点，定义了几种自用的新帧类型。

    第 5 个字节是非常重要的帧标志信息，可以保存 8 个标志位，携带简单的控制信息。常用的标志位有 END_HEADERS 表示头数据结束，相当于 HTTP/1 里头后的空行（“\r\n”），END_STREAM 表示单方向数据发送结束（即 EOS，End of Stream），相当于 HTTP/1 里 Chunked 分块结束标志（“0\r\n\r\n”）。

    报文头里最后 4 个字节是流标识符，也就是帧所属的“流”，接收方使用它就可以从乱序的帧里识别出具有相同流 ID 的帧序列，按顺序组装起来就实现了虚拟的“流”。

    流标识符虽然有 4 个字节，但最高位被保留不用，所以只有 31 位可以使用，也就是说，流标识符的上限是 2^31，大约是 21 亿。

    [HTTP/2 中的二进制帧](https://halfrost.com/http2-http-frames-definitions/)

3. **多路复用**

    使用**并发连接**和**域名分片**的方式来解决队头阻塞问题并没有真正从 HTTP 本身的层面解决问题，只是增加了 TCP 连接，分摊风险而已。而且这么做也有弊端，多条 TCP 连接会竞争有限的带宽，让真正优先级高的请求不能优先处理。

    HTTP/2 便从 HTTP 协议本身解决了队头阻塞问题：

    + **同域名下所有通信都在单个连接上完成**
    + **单个连接可以承载任意数量的双向数据流**

    数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装。

    同个域名只需要占用一个 TCP 连接，使用一个连接并行发送多个请求和响应,消除了因多个 TCP 连接而带来的延时和内存消耗：

    + 并行交错地发送多个请求，请求之间互不影响

    + 并行交错地发送多个响应，响应之间互不干扰

    **流是二进制帧的双向传输序列。**

    在 HTTP/2 连接上，虽然帧是乱序收发的，但只要它们都拥有相同的流 ID，就都属于一个流，而且在这个流里帧不是无序的，而是有着严格的先后顺序。

    在概念上，一个 HTTP/2 的流就等同于一个 HTTP/1 里的“请求 - 应答”。在 HTTP/1 里一个“请求 - 响应”报文来回是一次 HTTP 通信，在 HTTP/2 里一个流也承载了相同的功能。

    HTTP/2 的**流的特点**：

    - 流是可并发的，一个 HTTP/2 连接上可以同时发出多个流传输数据，也就是并发多请求，实现“多路复用”
    - 客户端和服务器都可以创建流，双方互不干扰
    - 流是双向的，一个流里面客户端和服务器都可以发送或接收数据帧，也就是一个“请求 - 应答”来回
    - 流之间没有固定关系，彼此独立，但流内部的帧是有严格顺序的
    - 流可以设置优先级，让服务器优先处理，比如先传 HTML/CSS，后传图片，优化用户体验
    - 流 ID 不能重用，只能顺序递增，客户端发起的 ID 是奇数，服务器端发起的 ID 是偶数
    - 在流上发送“RST_STREAM”帧可以随时终止流，取消接收或发送
    - 第 0 号流比较特殊，不能关闭，也不能发送数据帧，只能发送控制帧，用于流量控制

    ID 用完了该怎么办呢？这个时候可以再发一个**控制帧 GOAWAY** ，真正关闭 TCP 连接。

4. **服务器推送(Server Push)**

    在 HTTP/2 当中，服务器已经不再是完全被动地接收请求，响应请求，它也能新建**流**来给客户端发送消息。

    当 TCP 连接建立之后，比如浏览器请求一个 HTML 文件，服务器就可以在返回 HTML 的基础上，将 HTML 中引用到的其他资源文件一起返回给客户端，减少客户端的等待。

    服务端可以主动推送，客户端也有权利选择是否接收。如果服务端推送的资源已经被浏览器缓存过，浏览器可以通过发送 RST_STREAM 帧来拒收。主动推送也遵守同源策略，换句话说，服务器不能随便将第三方资源推送给客户端，而**必须是经过双方确认才行**。


## HTTP/3

QUIC 的新功能：

**0-RTT**

RTT：为数据完全发送完(完成最后一个比特推送到数据链路上)到收到确认信号的时间。

通过使用类似 TCP 快速打开的技术，缓存当前会话的上下文，在下次恢复会话的时候，只需要将之前的缓存传递给服务端验证通过就可以进行传输了。

什么是 0RTT 建立连接呢？

- 传输层 0RTT 就能建立连接
- 加密层 0RTT 就能建立加密连接

**多路复用**

QUIC 原生就实现了这个功能，并且传输的单个数据流可以保证有序交付且不会影响其他的数据流，这样的技术就解决了之前 TCP 存在的问题。

同一条 QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求，但是，QUIC 是基于 UDP 的，一个连接上的多个 stream 之间没有依赖，不存在 TCP 队头阻塞。虽然 stream2 的那个包需要重新传，但是 stream3、stream4 的包无需等待，就可以发给用户。

**加密认证的报文**

QUIC 的 packet 可以说是武装到了牙齿。除了个别报文比如 PUBLIC_RESET 和 CHLO，所有报文头部都是经过认证的，报文 Body 都是经过加密的。

**向前纠错机制**

每个数据包除了它本身的内容之外，还包括了部分其他数据包的数据，因此少量的丢包可以通过其他包的冗余数据直接组装而无需重传。向前纠错牺牲了每个数据包可以发送数据的上限，但是减少了因为丢包导致的数据重传，因为数据重传将会消耗更多的时间(包括确认数据包丢失、请求重传、等待新数据包等步骤的时间消耗)。

当然这种技术只能使用在丢失一个包的情况下，如果出现丢失多个包就不能使用纠错机制了，只能使用重传的方式了。


## HTTPS
**HTTP 是不安全的，为什么这么说呢？**

我们通常认为，如果通信过程具备以下四个特性：

+ **机密性**：数据只能由可信的人进行访问，对其他人是不可见的秘密。
+ **完整性**：数据在传输的过程中保持完整，没有被篡改。
+ **身份认证**：指的是能确认双方的真实身份。
+ **不可否认**：不能否认已经发生过的行为。

那么，我们就认为是“安全”的。

**那 HTTPS 是什么呢？**

HTTPS 其实就是**在 HTTP 上建立 SSL/TLS 加密层，并对传输数据进行加密**，是 HTTP 协议的安全版。

**为什么 HTTPS 能够保证安全呢？**

HTTPS 使得 HTTP 运行在安全的 SSL/TLS 协议上，**收发报文不再使用 Socket API，而是调用专门的安全接口**。

**让我们来认识下 SSL/TLS 为什么能保证安全？**

SSL 即安全套接层（Secure Sockets Layer），在 OSI 七层模型中处于会话层(第 5 层)。之前 SSL 出过三个大版本，当它发展到第三个大版本的时候才被标准化，成为 TLS（传输层安全，Transport Layer Security），并被当做 TLS1.0 的版本，准确地说，TLS1.0 = SSL3.1。

现在主流的版本是 TLS/1.2, 之前的 TLS1.0、TLS1.1 都被认为是不安全的，在不久的将来会被完全淘汰。因此我们接下来主要讨论的是 TLS1.2, 当然在 2018 年推出了更加优秀的 TLS1.3，大大优化了 TLS 握手过程。

TSL 由记录协议、握手协议、警告协议、变更密码规范协议、扩展协议等几个子协议组成，综合使用了对称加密、非对称加密、身份认证等密码学前沿技术。
+ **记录协议**（Record Protocol）规定了 TLS 收发数据的基本单位：记录（record）。它有点像是 TCP 里的 segment，所有的其他子协议都需要通过记录协议发出。但多个记录数据可以在一个 TCP 包里一次性发出，也并不需要像 TCP 那样返回 ACK。
+ **警报协议**（Alert Protocol）的职责是向对方发出警报信息，有点像是 HTTP 协议里的状态码。比如，protocol_version 就是不支持旧版本，bad_certificate 就是证书有问题，收到警报后另一方可以选择继续，也可以立即终止连接。
+ **握手协议**（Handshake Protocol）是 TLS 里最复杂的子协议，要比 TCP 的 SYN/ACK 复杂的多，浏览器和服务器会在握手过程中协商 TLS 版本号、随机数、密码套件等信息，然后交换证书和密钥参数，最终双方协商得到会话密钥，用于后续的混合加密系统。
+ **变更密码规范协议**（Change Cipher Spec Protocol），它非常简单，就是一个“通知”，告诉对方，后续的数据都将使用加密保护。那么反过来，在它之前，数据都是明文的。

浏览器与服务器在使用 TLS 建立连接时需要选择一组恰当的加密算法来实现安全通信，这些算法的组合被称为“**密码套件**”。

TLS 的密码套件命名非常规范，格式固定。基本形式为：**密钥交换算法() + 签名算法() + 对称加密算法(保证机密性) + 摘要算法()**。

**加密算法有两种：对称加密算法和非对称加密算法**

+ **对称加密算法**：加密和加密使用的密钥都是同一个，是“对称”的。

  只要保证了密钥的安全性，那么整个通信过程就可以说具备了机密性。

  TLS 中有非常多的对称加密算法可供选择：RC4，DES，3DES，AES，ChaCha20 等。前三种都认为是不安全的，通常禁止使用。目前常用的有 AES 和 ChaCha20。

  + **AES**（Advanced Encryption Standard），密钥长度可以是 128、192 或 256。它是 DES 的替代者，安全强度很高，性能也很好，是使用最广泛的对称加密算法。
  + **ChaCha20**，由 Google 设计的对称加密算法，密钥长度固定为 256。纯软件性能要好于 AES，也是一个不错的对称加密算法。

  分组模式：让算法用固定的长度的密钥加密任意长度的明文。最新的分组模式被称为 AEAD，常使用的是 GCM，CCM，Poly1305。

  将上面的这些组合起来，就可以得到 HTTPS 密码套件中定义的对称加密算法。
  ```
  AES128-GCM // 密钥长度为 128 位的 AES 算法，使用 GCM 分组模式
  ChaCha20-Poly1305 // ChaCha20 算法，使用 Poly1305 分组模式
  ```
  对称加密算法存在这一个很大的问题：如何将密钥安全的传递给对方呢(密钥交换)？

  为了解决这个问题，非对称加密算法应运而生。

+ **非对称加密算法**：也称公钥加密算法，他有两个密钥，一个叫公钥，一个叫私钥。两个密钥是不同的，但公钥可以公开给任何人使用，而密钥必须严格保密。

  公钥和私钥有个特别的“单向”性。谁人都可以用来进行加密解密，但公钥加密后只能用私钥解密，私钥加密后也只能用公钥解密。

  非对称加密可以解决密钥交换的问题。网站秘密保管私钥，在网上任意公布公钥，想要登录网站只要公钥加密就行了，密文只能由私钥持有者才能解密。

  TLS 中的非对称加密算法：DH，DSA，RSA，ECC 等。
  + **RSA**：它的安全性基于“整数分解”的数学难题，使用两个超大的素数乘积作为生成密钥的材料。十年前 RSA 的密钥推荐长度是 1024，但随着计算机性能的提升，1024 已经不安全了，至少需要 2048。
  + **ECC**：它基于“椭圆曲线离散对数”的数学难题，使用特定的曲线方程和基点生成公钥和私钥，子算法 ECDHE 用于密钥交换，ECDSA 用于数字签名。目前常用的曲线是：P-256 和 x25519。

  非对称加密算法保证了安全，那它是否有什么问题呢？答案是肯定的，非对称加密算法都是基于复杂的数学问题，运行速度很慢，如果仅使用非对称加密算法，虽然安全得到了保证，但是通信速度极其慢，实用性为 0。

  那么应该如何解决这个问题呢？我们可以把对称加密算法和非对称加密算法结合起来，取长补短，这也就是如今 TLS 中使用的“混合加密”。

+ **混合加密**：在交换密钥环节使用非对称加密方式，之后的建立通信交换报文阶段则使用对称加密方式。

  具体做法是：发送密文的一方使用对方的公钥进行加密处理“对称加密算法的密钥”，然后对方用自己的私钥解密拿到“对称加密算法的密钥”，这样可以确保交换的密钥是安全的前提下，使用对称加密方式进行通信。

HTTPS 采用对称加密和非对称加密两者并用的混合加密机制保证了通信的机密性，但这还是不够安全，如何保证通信的完整性呢？

**摘要算法**：是实现完整性的主要手段，也就是通常说的散列函数、哈希函数。(可以将它理解成一种特殊的压缩算法，能够把任意长度的数据“压缩”成固定长度且独一无二的“摘要”字符串，就好像给数据生成了指纹)

目前 TLS 推荐使用的是 SHA-2 摘要算法，常用的有这 3 种：SHA224、SHA256、SHA384，分别能够生成 28，32，48 字节的摘要字符串。

摘要算法保证了“数字摘要”和原文是完全相等的，所以只需在原文后附上它的摘要，就能够保证数据的完整性了。

真正的完整性还是建立在机密性之上的。

通过混合加密和摘要算法我们保证了 HTTPS 的机密性和完整性，那么如何实现身份认证和不可否认呢？

**数字签名**：使用非对称加密算法，使用私钥进行加密，公钥进行解密。(私钥只加密摘要，提升效率)

通过综合使用对称加密算法，非对称加密算法和摘要算法，我们已经实现了安全的四大特性了，那是不是已经完美了呢？

答案是否定的，还存在一个“公钥安全”的问题。因为谁都可以发布公钥，无法判断公钥的真实性。

**CA（Certifivate Authority）**,证书认证机构。由他给各个公钥进行签名认证，用自身信誉保证公钥是无法伪造的，可信的。

CA 对公钥的签名认证会将包含的序列号，用途，颁发者，有效时间等信息打包签名，形成“数字证书”。

签名的产生算法：使用摘要算法计算公开的明文信息的摘要，然后，采用 CA 的私钥对摘要进行加密，密文即签名。

客户端 Client 读取证书中的相关的明文信息，采用相同的摘要算法计算得到摘要，然后，利用对应 CA 的公钥解密签名数据，对比证书摘要，如果一致，则可以确认证书的合法性，即服务器的公开密钥是值得信赖的。

**TLS 的握手过程(ECDHE)：**

1. 在 TCP 建立连接之后，浏览器会首先发一个“Client Hello”消息，里面有客户端的版本号、支持的密码套件，还有一个随机数（Client Random），用于后续生成会话密钥。

2. 服务器收到“Client Hello”后，会返回一个“Server Hello”消息。把版本号对一下，也给出一个随机数（Server Random），然后从客户端的列表里选一个作为本次通信使用的密码套件，如 “TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384”。
3. 服务器为了证明自己的身份，把证书也发给了客户端（Server Certificate）。
4. 因为服务器选择了 ECDHE 算法，所以它会在证书后发送“Server Key Exchange”消息，里面是椭圆曲线的公钥（Server Params），用来实现密钥交换算法，再加上自己的私钥签名认证。
5. 之后是“Server Hello Done”消息。这样第一个消息往返就结束了（两个 TCP 包），结果是客户端和服务器通过明文共享了三个信息：Client Random、Server Random 和 Server Params。
6. 客户端这时也拿到了服务器的证书，开始走证书链逐级验证，确认证书的真实性，再用证书公钥验证签名，就确认了服务器的身份。
7. 客户端按照密码套件的要求，也生成一个椭圆曲线的公钥（Client Params），用“Client Key Exchange”消息发给服务器。
8. 客户端和服务器手里都拿到了密钥交换算法的两个参数（Client Params、Server Params），就用 ECDHE 算法一阵算，算出了一个新的东西，叫“Pre-Master”，其实也是一个随机数。
9. 现在客户端和服务器手里有了三个随机数：Client Random、Server Random 和 Pre-Master。用这三个作为原始材料，就可以生成用于加密会话的主密钥，叫“Master Secret”。
10. 有了主密钥和派生的会话密钥，握手就快结束了。客户端发一个“Change Cipher Spec”，然后再发一个“Finished”消息，把之前所有发送的数据做个摘要，再加密一下，让服务器做个验证。
11. 服务器也是同样的操作，发“Change Cipher Spec”和“Finished”消息，双方都验证加密解密 OK，握手正式结束，后面就收发被加密的 HTTP 请求和响应了。

**HTTPS 与 HTTP 的区别**

+ HTTPS 比 HTTP 更加安全，对搜索引擎更友好，利于SEO，谷歌、百度会优先索引 HTTPS 网页
+ HTTPS 需要用到 SSL 证书，而 HTTP 不用
+ HTTPS 标准端口 443，HTTP标准端口 80
+ HTTPS 基于传输层，HTTP 基于应用层
+ HTTPS 在浏览器显示绿色安全锁，HTTP 没有显示


## DNS
DNS(Domain Name System) 的作用非常简单，就是根据域名查出 IP 地址。

DNS 域名系统，**运行 UDP 协议之上，使用端口 43**。

**域名的形式**

域名是一个有层次的结构，是一串用“.”分隔的多个单词，最右边的被称为“顶级域名”，然后是“二级域名”，层级关系向左依次降低。

域名本质上还是个名字空间系统，使用多级域名就可以划分出不同的国家、地区、组织、公司、部门，每个域名都是独一无二的，可以作为一种身份的标识。

**域名的解析**

DNS 的核心系统是一个三层的树状、分布式服务，基本对应域名的结构：
+ 根域名服务器（Root DNS Server）：管理顶级域名服务器，返回“com”“net”“cn”等顶级域名服务器的 IP 地址 (目前全世界共有 13 组根域名服务器，又有数百台的镜像，保证一定能够被访问到)
+ 顶级域名服务器（Top-level DNS Server）：管理各自域名下的权威域名服务器，比如 com 顶级域名服务器可以返回 apple.com 域名服务器的 IP 地址
+ 权威域名服务器（Authoritative DNS Server）：管理自己域名下主机的 IP 地址，比如 apple.com 权威域名服务器可以返回 www.apple.com 的 IP 地址

**DNS 查询**

浏览器缓存 -> 操作系统 dns cache -> hosts 文件 -> 非权威域名服务器 -> 根域名服务器 -> 顶级域名服务器 -> 二级域名服务器 -> 权威域名服务器。

一般浏览器向本地DNS服务器发送请求是递归查询的，本地 DNS 服务器向其他域名服务器请求的过程是迭代查询的过程。
+ 递归查询：指的是查询请求发出后，域名服务器代为向下一级域名服务器发出请求，最后向用户返回查询的最终结果。使用递归查询，用户只需要发出一次查询请求。
![递归查询](https://user-images.githubusercontent.com/34484322/89356512-95168e80-d6f0-11ea-93aa-c4f59fd36942.png)
+ 迭代查询：指的是查询请求后，域名服务器返回单次查询的结果。下一级的查询由用户自己请求。使用迭代查询，用户需要发出多次的查询请求。
![迭代查询](https://user-images.githubusercontent.com/34484322/89356522-99db4280-d6f0-11ea-9bf9-851b25bd16c3.png)

**DNS 缓存**

缓存也很好理解，在一个请求中，当某个 DNS 服务器收到一个 DNS 回答后，它能够回答中的信息缓存在本地存储器中。

返回的资源记录中的 TTL 代表了该条记录的缓存的时间。


## CDN
CDN(Content Delivery Network)，内容分发网络。

**为什么要使用 CDN？**

首先，因为地理位置的距离导致的传输延迟就会变得比较明显。

比如，北京到广州直线距离大约是 2000 公里，按照刚才的 20 万公里 / 秒来算的话，发送一个请求单程就要 10 毫秒，往返要 20 毫秒，即使什么都不干，这个“硬性”的时延也是躲不过的。

还有，网络中还存在许多的路由器、网关，数据每经过一个节点，都要停顿一下，在二层、三层解析转发，这也会消耗一定的时间，带来延迟。

所以 CDN 就出现了，它就是专门为解决“长距离”上网络访问速度慢而诞生的一种网络应用服务。

**CDN 的最核心原则是“就近访问”。**

CDN 投入了大笔资金，在全国、乃至全球的各个大枢纽城市都建立了机房，部署了大量拥有高存储高带宽的节点，构建了一个专用网络。

这个网络是跨运营商、跨地域的，虽然内部也划分成多个小网络，但它们之间用高速专有线路连接，是真正的“信息高速公路”，基本上可以认为不存在网络拥堵。

有了这个高速的专用网之后，CDN 就要“分发”源站的“内容”了，用到的就是“缓存代理”技术。

于是，用户在上网的时候就不直接访问源站，而是访问离他“最近的”一个 CDN 节点，术语叫“边缘节点”（edge node），其实就是缓存了源站内容的代理服务器，这样一来就省去了“长途跋涉”的时间成本，实现了“网络加速”。

**CDN 都能加速什么样的“内容”呢？**

资源按照是否可缓存又分为**静态资源**和**动态资源**。

+ 静态资源

  指得失数据内容“静态不变”，任何时候来访问都是一样的，比如图片、音频。

+ 动态资源

  指的是数据内容是“动态变化”的，也就是由后台服务计算生成的，每次访问都不一样，比如商品的库存、微博的粉丝数等。

只有**静态资源才能够被缓存加速、就近访问**，而动态资源只能由源站实时生成，即使缓存了也没有意义。

不过，如果**动态资源指定了 Cache-Control**，允许缓存短暂的时间，那它在这段时间里也就变成了静态资源，可以被 CDN 缓存加速。

**CDN 的负载均衡**

+ **全局负载均衡(GSLB)**
  
    主要的职责是当用户接入网络的时候在 CDN 专网中挑选出一个**最佳**节点提供服务，解决的是用户如何找到“最近的”边缘节点，对整个 CDN 网络进行“负载均衡”。
    
    GSLB 最常见的实现方式是**DNS 负载均衡**。
    
    加入 CDN 后，权威 DNS 返回的不是 IP 地址，而是一个 **CNAME**( Canonical Name ) 别名记录，指向的就是 CDN 的 GSLB。
    
    因为没拿到 IP 地址，于是本地 DNS 就会向 GSLB 再发起请求，这样就进入了 CDN 的全局负载均衡系统，开始“智能调度”，主要的依据有这么几个：
    
    + 看用户的 IP 地址，查表得知地理位置，找相对最近的边缘节点
    + 看用户所在的运营商网络，找相同网络的边缘节点
    + 检查边缘节点的负载情况，找负载较轻的节点
    + 其他，比如节点的“健康状况”、服务能力、带宽、响应时间等
    
    GSLB 把这些因素综合起来，用一个复杂的算法，最后找出一台“最合适”的边缘节点，把这个节点的 IP 地址返回给用户。
    
+ **缓存系统**
  
    使用 HTTP 缓存代理技术，缓存命中就返回给用户，否则就要回源。缓存系统只能有选择地缓存那些最常用的那些资源。
    这里就有两个 CDN 的关键概念：
    
    + **命中**：指用户访问的资源恰好在缓存系统里，可以直接返回给用户。
    + **回源**：正相反，缓存里没有，必须用代理的方式回源站取。


## WebSocket
[WebSocket](https://halfrost.com/websocket/)

## Web 安全
**XSS(Cross Site Scripting 跨站脚本攻击)**

XSS 攻击是指浏览器中**执行恶意脚本**(无论是跨域还是同域)，从而**拿到用户的信息**并进行操作。

一般可以完成下面这些事情：
+ 窃取 Cookie。
+ 监听用户行为，比如输入账号密码后直接发送到黑客服务器。
+ 修改 DOM 伪造登录表单。
+ 在页面中生成浮窗广告。

XSS 攻击的实现方式：
+ **存储型**
  
    将恶意脚本存储了起来，存储型的 XSS 将脚本存储到了服务端的数据库，然后在客户端执行这些脚本，从而达到攻击的效果。
    
    常见的场景是留言评论区提交一段脚本代码，如果前后端没有做好转义的工作，那评论内容存到了数据库，在页面渲染过程中直接执行, 相当于执行一段未知逻辑的 JS 代码，是非常恐怖的。
    
+ **反射型**
  
    反射型XSS指的是恶意脚本作为网络请求的一部分。
    
    比如输入
    
    ```
    http://sanyuan.com?q=<script>alert("你完蛋了")</script>
    ```
    在服务器端会拿到 q 参数,然后将内容返回给浏览器端，浏览器将这些内容作为 HTML 的一部分解析，发现是一个脚本，直接执行，这样就被攻击了。
    
    之所以叫它反射型，是因为恶意脚本是通过作为网络请求的参数，经过服务器，然后再反射到 HTML 文档中，执行解析。
    
    和存储型不一样的是，服务器并不会存储这些恶意脚本。
    
+ **文档型**
  
    文档型的 XSS 攻击并不会经过服务端，而是作为中间人的角色，在数据传输过程劫持到网络数据包，然后修改里面的 html 文档。
    
    这样的劫持方式包括 **WIFI 路由器劫持**或者**本地恶意软件**等。

防御方法：
+ 千万不要相信任何用户的输入，无论是在前端和服务端，都要**对用户的输入进行转码或者过滤**。
+ 利用 **CSP**，它的核心思想就是服务器决定浏览器加载哪些资源，它的功能有：
    - 限制其他域下的资源加载
    - 禁止向其它域提交数据
    - 提供上报机制，能帮助我们及时发现 XSS 攻击
+ 利用 **HttpOnly**，很多 XSS 攻击脚本都是用来窃取Cookie, 而设置 Cookie 的 HttpOnly 属性后，JavaScript 便无法读取 Cookie 的值。

**CSRF(Cross-site request forgery 跨站请求伪造)**

CSRF 攻击指的是**黑客诱导用户点击链接**，**打开黑客的网站**，然后黑客**利用用户目前的登录态**发起**跨站请求**。

可能会做下面的事：
+ 自动发 GET 请求，携带了相应的 cookie，然后进行相应的各种操作，可以是转账汇款以及其他的恶意操作。
+ 自动发 POST 请求，携带相应的用户 cookie 信息，让服务器误以为是一个正常的用户在操作，让各种恶意的操作变为可能。
+ 诱导点击发送 GET 请求

防御方法：
+ 利用 Cookie 的 **SameSite** 属性

+ **验证来源站点**，通过请求头中的 **Origin** 和 **Referer** 字段

    + Origin 只包含域名信息
    + Referer 包含了具体的 URL 路径

    当然，这两者都是可以伪造的，通过 Ajax 中自定义请求头即可，安全性略差。

+ **CSRF Token（JWT）**
  
    浏览器向服务器发送请求时，服务器生成一个字符串，将其植入到返回的页面中。
    
    然后浏览器如果要发送请求，就必须带上这个字符串，然后服务器来验证是否合法，如果不合法则不予响应。
    
    这个字符串也就是 CSRF Token，通常第三方站点无法拿到这个 token，因此也就是被服务器给拒绝。

+ **验证码**


## 常见面试题
1. **GET 和 POST 的区别？**
    + 从缓存的角度，GET 请求会被浏览器主动缓存下来，留下历史记录，而 POST 默认不会。
    + 从编码的角度，GET 只能进行 URL 编码，只能接收 ASCII 字符，而 POST 没有限制。
    + 从参数的角度，GET 一般放在 URL 中，因此不安全，POST 放在请求体中，更适合传输敏感信息。
    + 从幂等性的角度，GET 是幂等的，而 POST 不是。(幂等表示执行相同的操作，结果也是相同的)
    + 从 TCP 的角度，GET 请求会把请求报文一次性发出去，而 POST 会分为两个 TCP 数据包，首先发 header 部分，如果服务器响应 100(continue)， 然后发 body 部分。(火狐浏览器除外，它的 POST 请求只发一个 TCP 包)


2. **什么是简单请求和复杂请求？**

    若请求满足所有下述条件，则该请求可视为“简单请求”：
    + 使用下列方法之一：
        + GET
        + HEAD
        + POST
    + 除了被用户代理自动设置的首部字段（例如 Connection ，User-Agent）和在 Fetch 规范中定义为 禁用首部名称 的其他首部，允许人为设置的字段为 Fetch 规范定义的 对 CORS 安全的首部字段集合。该集合为：
        + Accept
        + Accept-Language
        + Content-Language
        + Content-Type （需要注意额外的限制）
        + DPR
        + Downlink
        + Save-Data
        + Viewport-Width
        + Width
    + Content-Type 的值仅限于下列三者之一：
        + text/plain
        + multipart/form-data
        + application/x-www-form-urlencoded
    + 请求中的任意 XMLHttpRequestUpload 对象均没有注册任何事件监听器；XMLHttpRequestUpload 对象可以使用 XMLHttpRequest.upload 属性访问。
    + 请求中没有使用 ReadableStream 对象。

    非简单请求即为复杂请求。

    简单请求和复杂请求针对 CORS 的设置有着不同的处理。[MDN](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Access_control_CORS)


3. **OPTIONS 方法有什么用？**
    + OPTIONS 请求与 HEAD 类似，一般也是用于客户端查看服务器的性能。
    + 这个方法会请求服务器返回该资源所支持的所有 HTTP 请求方法，该方法会用'*'来代替资源名称，向服务器发送 OPTIONS 请求，可以测试服务器功能是否正常。
    + JS 的 XMLHttpRequest 对象进行 CORS 跨域资源共享时，对于复杂请求，就是使用 OPTIONS 方法发送嗅探请求，以判断是否有对指定资源的访问权限。


4. **头部信息中的 Content 相关字段了解多少？**
   
    + 数据格式：Content-Type 和 Accept
    
        - text: text/html, text/plain, text/css 等
        - image: image/gif, image/jpeg, image/png 等
        - audio/video: audio/mpeg, video/mp4 等
        - application: application/json, application/javascript, application/pdf, application/octet-stream
    
    + 压缩方式：Content-Encoding 和 Accept-Encoding
    
        - gzip: 当今最流行的压缩格式
        - deflate: 另外一种著名的压缩格式
        - br: 一种专门为 HTTP 发明的压缩算法
    
    + 支持语言：Content-Language 和 Accept-Language
    
    + 字符集：Content-Type 的 charset 和 Accept-Charset 的 charset


5. **如何解决队头阻塞的问题？**
    
    HTTP 传输是基于**请求-应答**的模式进行的，报文必须是一发一收。
    
    需要注意的是，里面的任务被放在一个任务队列中串行执行，一旦队首的请求处理太慢，就会阻塞后面请求的处理。
    
    - **并发连接**
    
      对于一个域名允许分配多个长连接，相当于增加了任务队列，不至于一个队列的任务阻塞其它所有任务。
    
      在 RFC2616 规定过客户端最多并发 2 个连接，不过事实上在现在的浏览器标准中，这个上限要更多，在 Chrome 中是 6 个。
    
    - **域名分片**
    
      一个域名可以并发 6 个长连接，那就多分几个域名。
    
      比如一个域名下可以分出非常多的二级域名，而它们都指向同样的一台服务器，这样能够并发的长连接数就更多。


6. **DNS 为什么使用 UDP 协议作为传输层协议？**

    DNS 使用 UDP 协议作为传输层协议的主要原因是**为了避免使用 TCP 协议时造成的连接时延**。
    + 为了得到一个域名的 IP 地址，往往会向多个域名服务器查询，如果使用 TCP 协议，那么每次请求都会存在连接时延，这样使 DNS 服务变得很慢。
    + 大多数的地址查询请求，都是浏览器请求页面时发出的，这样会造成网页的等待时间过长。


7. **介绍一下 Connection: keep-alive（长连接）**
    
HTTP 协议采用“请求-应答”模式，当使用普通模式，即非 Keep-Alive 模式时，对于每个请求应答客户和服务器都要新建一个连接，完成之后立即断开连接（HTTP协议为无连接的协议）。
    
当使用 Keep-Alive 模式（又称持久连接、连接重用）时，Keep-Alive 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive 功能**避免了建立或者重新建立连接**。
    
keep-alive 技术的创建目的，能在使得**多次 HTTP 请求重用同一个 TCP 连接**，从而减少创建/关闭多个 TCP 连接的开销。
    
    HTTP/1.0 中，keep-alive 默认是关闭的，需要在 head 加入**Connection: Keep-Alive**，才能启用长连接。
    
    HTTP/1.1 中，默认启用 Keep-Alive，只有加入**Connection: close**，才关闭。


8. **SSL 连接断开后如何恢复？**

    一共有两种方法来恢复断开的 SSL 连接，一种是使用 session ID，一种是 session ticket。
    + **session ID**
    
      使用 session ID 的方式，每一次的会话都有一个编号，当对话中断后，下一次重新连接时，只要客户端给出这个编号，服务器如果有这个编号的记录，那么双方就可以继续使用以前的秘钥，而不用重新生成一把。
    
      目前所有的浏览器都支持这一种方法。但是这种方法有一个缺点是，s**ession ID 只能够存在一台服务器上**，如果我们的请求通过负载平衡被转移到了其他的服务器上，那么就无法恢复对话。
    
    + **session ticket**
    
      session ticket 是服务器在上一次对话中发送给客户的，这个 ticket 是加密的，只有服务器能够解密，里面包含了本次会话的信息，比如对话秘钥和加密方法等。
    
      这样不管我们的请求是否转移到其他的服务器上，当服务器将 ticket 解密以后，就能够获取上次对话的信息，就不用重新生成对话秘钥了。


9. **短轮询、长轮询和 WebSocket 间的区别？**
    
    + **短轮询**
    
      浏览器每隔一段时间向浏览器发送 http 请求，服务器端在收到请求后，不论是否有数据更新，都直接进行响应。
    
      这种方式实现的即时通信，本质上还是浏览器发送请求，服务器接受请求的一个过程，通过让客户端不断的进行请求，使得客户端能够模拟实时地收到服务器端的数据的变化。

      优缺点：
    
        + 优点：这种方式比较简单，易于理解。
        + 缺点：这种方式由于需要不断的建立 http 连接，严重浪费了服务器端和客户端的资源。当用户增加时，服务器端的压力就会变大，这是很不合理的。
    
    + **长轮询**

      首先由客户端向服务器发起请求，当服务器收到客户端发来的请求后，服务器端不会直接进行响应，而是先将这个请求挂起，然后判断服务器端数据是否有更新。
    
      如果有更新，则进行响应，如果一直没有数据，则到达一定的时间限制才返回。客户端 JavaScript 响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接。

      优缺点：
    
        + 优点：明显减少了很多不必要的 http 请求次数，相比之下节约了资源。
        + 缺点：连接挂起也会导致资源的浪费。
    
    + **WebSocket**
    
      WebSocket 是 HTML5 定义的一个新协议，与传统的 http 协议不同，该协议允许由服务器主动的向客户端推送信息。
    
      使用 WebSocket 协议的缺点是在**服务器端的配置比较复杂**。
    
      WebSocket 是一个全双工的协议，通信双方是平等的，可以相互发送消息。
    
10. **说一说正向代理和反向代理**


11. **负载均衡的两种实现方式？**
    + **使用反向代理**
    
      用户的请求都发送到反向代理服务上，然后由反向代理服务器来转发请求到真实的服务器上，以此来实现集群的负载平衡。
    
    + **DNS**
    
      DNS 可以用于在冗余的服务器上实现负载平衡。
    
      因为现在一般的大型网站使用多台服务器提供服务，因此一个域名可能会对应多个服务器地址。
    
      当用户向网站域名请求的时候，DNS 服务器返回这个域名所对应的服务器 IP 地址的集合，但在每个回答中，会循环这些 IP 地址的顺序，用户一般会选择排在前面的地址发送请求。
    
      以此将用户的请求均衡的分配到各个不同的服务器上，这样来实现负载均衡。
    
      这种方式有一个缺点就是，由于 DNS 服务器中存在缓存，所以有可能一个服务器出现故障后，域名解析仍然返回的是那个 IP 地址，就会造成访问的问题。


12. **HTTP 性能优化**

    从 HTTP 最基本的“**请求 - 应答**”模型来着手，在这个模型里有两个角色：客户端和服务器，还有中间的传输链路，考查性能就可以看这三个部分。
    
    + **CDN**
    
    + 服务端应该选用**高性能的 Web 服务器**，开启 **HTTP 长连接**，提升 TCP 的传输效率
    
    + **开源**：开发网站服务器自身的潜力，在现有条件不变的情况下尽量挖掘出更多的服务能力。
        
        + 启用 TCP 的新特性 “**TCP Fast Open**”
        
    + **节流**
        
        + 使用 HTTP 协议内置的“**数据压缩**”编码，不仅可以选择标准的 gzip，还可以积极尝试新的压缩算法 br，它有更好的压缩效果。
        
        + HTML/CSS/JavaScript 属于纯文本，就可以采用特殊的“**压缩**”，去掉源码里多余的空格、换行、注释等元素。
        
        + 图片在 HTTP 传输里占有非常高的比例，虽然它本身已经被压缩过了，不能被 gzip、br 处理，但仍然有优化的空间。
        
          比如说，去除图片里的拍摄时间、地点、机型等元数据，适当降低分辨率，缩小尺寸。图片的格式也很关键，**尽量选择高压缩率的格式，有损格式应该用 JPEG，无损格式应该用 Webp 格式**。
        
        + 小文本或者小图片，还有一种叫做“**资源合并**”（Concatenation）的优化方式，就是把许多小资源合并成一个大资源，用一个请求全下载到客户端，然后客户端再用 JavaScript、CSS 切分后使用，好处是节省了请求次数，但缺点是处理比较麻烦。
        
        + **减少使用 Cookie**，减少 Cookie 记录的数据量，使用 domain 和 path 属性限定 Cookie 的作用域，尽可能减少 Cookie 的传输。如果客户端是现代浏览器，还可以使用 HTML5 里定义的 Web Local Storage，避免使用 Cookie。
        
        + DNS 解析域名会耗费不少的时间，如果网站拥有多个域名，那么域名解析获取 IP 地址就是一个不小的成本，所以应当**适当“收缩”域名**，限制在两三个左右，减少解析完整域名所需的时间，让客户端尽快从系统缓存里获取解析结果。
        
        + 重定向引发的客户端延迟也很高，它不仅增加了一次请求往返，还有可能导致新域名的 DNS 解析，是 HTTP 前端性能优化的“大忌”。除非必要，应当**尽量不使用重定向**，或者**使用 Web 服务器的“内部重定向”**。
        
    + **缓存**
    
    + **升级 HTTP/2**
        
        需要注意，一些在 HTTP/1.1 里的优化手段到了 HTTP/2 里会有“反效果”。
        
        + 对于 HTTP/2 来说，一个域名使用一个 TCP 连接才能够获得最佳性能，如果开多个域名，就会浪费带宽和服务器资源，也会降低 HTTP/2 的效率，所以“**域名收缩**”在 HTTP/2 里是必须要做的。
        + “资源合并”在 HTTP/1 里减少了多次请求的成本，但在 HTTP/2 里因为有头部压缩和多路复用，传输小文件的成本很低，所以**合并就失去了意义**。而且“资源合并”还有一个缺点，就是降低了缓存的可用性，只要一个小文件更新，整个缓存就完全失效，必须重新下载。